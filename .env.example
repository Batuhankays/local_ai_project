# Ollama Ayarları (Offline LLM)
# Önerilen: llama3.1:8b (Türkçe çok iyi, 4.7GB)
# Alternatifler: gemma2:9b, llama3.2:3b (düşük RAM için)
OLLAMA_MODEL=llama3.1:8b
OLLAMA_URL=http://localhost:11434

# RAG Ayarları
CHUNK_SIZE=800
CHUNK_OVERLAP=200
TOP_K_RESULTS=3

# Embedding Model (Offline)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Vektör DB
VECTOR_DB_PATH=./data/vector_store
VECTOR_DB_TYPE=faiss
